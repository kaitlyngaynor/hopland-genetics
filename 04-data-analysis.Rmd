---
title: "Data analysis"
author: "Kaitlyn"
date: "2019-11-20"
output: md_document
editor_options:
  chunk_output_type: console
---

Set working directory and load data.

```{r setup, message = F, warning = F}
library(lme4)
library(tidyverse)
library(here)

# import cleaned file
genotypes <- read_csv(here::here("data", "cleaned-triplicates-genotypes-qpcr.csv"))
```

## Generalized Linear Mixed Models

We have a tricky modeling situation with the dependent variable—it is effectively a proportion (number of markers working out of 10 markers), and is bounded between 0 and 10 (or 0 and 1, if calculated as a true proportion). Furthermore, it is not normally distributed, but instead 0- and 1-inflated (most of the values are 0 or 1). When Googling, I ran into these ZOIB models (zero-one inflated beta models) which are a little confusing to me but seems promising?? https://journal.r-project.org/archive/2015/RJ-2015-019/RJ-2015-019.pdf They entail Bayesian inference and are a little tricky. I didn't go down this route.

We could instead treat the dependent variable as a binary variable (worked vs not worked, with the "worked" cut-off being 8 or 10), which simplifies our analysis greatly, and also may actually be more meaningful, since we don't actually care about the difference between 4 worked and 5 worked. So this is the route that I took. I'm open to feedback, and of course open to people playing around with the ZOIB models on their own (though am not sure I have the capacity to open that can of worms myself, ha).

I used sample (lab_id) as a random effect, to control for the fact that we tested the same samples in triplicate across methods. I tested both storage method and condition as fixed effects, in addition to running a null model (with only the random effect).

#### Working samples (>= 8 markers)

```{r model working}
genotypes$working <- as.factor(genotypes$working)

# no variables—just random effect
fit0 <- glmer(working ~ (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit0) # AIC = 409.2

# effect of condition only
fit1 <- glmer(working ~ cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1) # AIC = 389.8
 
# effect of condition only (coarse categories) - NEED TO UPDATE THIS
#fit1.5 <- glmer(working ~ cond.coarse + (1 | lab_id), family = binomial("logit"), data = genotypes)
#summary(fit1.5) # AIC = 404.2

# effect of storage only
fit2 <- glmer(working ~ stor + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit2) # AIC = 382.9

# effect of storage and condition
fit3 <- glmer(working ~ stor + cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit3) # AIC = 365.1

# effect of storage and condition (interacting)
fit4 <- glmer(working ~ stor * cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit4) # AIC = 366
```

#### Perfect samples (all 10 markers)

```{r model perfect}
genotypes$perfect <- as.factor(genotypes$perfect)

# no variables—just random effect
fit0 <- glmer(perfect ~ (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit0) # AIC = 428.5

# effect of condition only
fit1 <- glmer(perfect ~ cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1) # AIC = 409.6

# effect of condition only (coarse categories)
#fit1.5 <- glmer(perfect ~ cond.coarse + (1 | lab_id), family = binomial("logit"), data = genotypes)
#summary(fit1.5) # AIC = 421.8

# effect of storage only
fit2 <- glmer(perfect ~ stor + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit2) # AIC = 404.1

# effect of storage and condition
fit3 <- glmer(perfect ~ stor + cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit3) # AIC = 385.2

# effect of storage and condition (interacting)
fit4 <- glmer(perfect ~ stor * cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit4) # AIC = 386.4
```

The best models (lowest AIC) for both working genotypes (with at least 8 amplifying markers) and perfect genotypes (all 10 markers working) include both storage and condition (but NOT the interaction between the two), as well as sample ID as a random effect. This suggests that both storage method and sample condition have important (but independent) effects on whether or not a sample works.

I tested two versions of condition score: one numerical (with 0.5 intervals), and one as a factor (coarser, with four categories), and the numerical one was better in both models.
