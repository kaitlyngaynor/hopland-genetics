---
title: "Data analysis"
author: "Kaitlyn"
date: "2019-11-20"
output: md_document
editor_options:
  chunk_output_type: console
---

Set working directory and load data.

```{r setup, message = F, warning = F}
library(lme4)
library(tidyverse)
library(here)

# import cleaned file
genotypes <- read_csv(here::here("data", "cleaned-triplicates-genotypes-qpcr.csv"))

genotypes$cond.coarse <- fct_collapse(as.factor(genotypes$cond), 
                                           Slimy = c("1", "1.5"),
                                           Wet = c("2", "2.5"),
                                           Shiny = c("3", "3.5"),
                                           Dull = c("4"))
```

## GLMMs for microsat genotyping

We have a tricky modeling situation with the dependent variable—it is effectively a proportion (number of markers working out of 10 markers), and is bounded between 0 and 10 (or 0 and 1, if calculated as a true proportion). Furthermore, it is not normally distributed, but instead 0- and 1-inflated (most of the values are 0 or 1). When Googling, I ran into these ZOIB models (zero-one inflated beta models) which are a little confusing to me but seems promising?? https://journal.r-project.org/archive/2015/RJ-2015-019/RJ-2015-019.pdf They entail Bayesian inference and are a little tricky. I didn't go down this route.

We could instead treat the dependent variable as a binary variable (worked vs not worked, with the "worked" cut-off being 8 or 10), which simplifies our analysis greatly, and also may actually be more meaningful, since we don't actually care about the difference between 4 worked and 5 worked. So this is the route that I took. I'm open to feedback, and of course open to people playing around with the ZOIB models on their own (though am not sure I have the capacity to open that can of worms myself, ha).

I used sample (lab_id) as a random effect, to control for the fact that we tested the same samples in triplicate across methods. I tested both storage method and condition as fixed effects, in addition to running a null model (with only the random effect).

#### Working samples (>= 8 markers)

```{r model working}
genotypes$working <- as.factor(genotypes$working)

# no variables—just random effect
fit0 <- glmer(working ~ (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit0) # AIC = 405.7

# effect of condition only
fit1 <- glmer(working ~ cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1) # AIC = 386.5

# effect of condition only (coarse categories) 
fit1.5 <- glmer(working ~ cond.coarse + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1.5) # AIC = 389

# effect of storage only
fit2 <- glmer(working ~ stor + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit2) # AIC = 378.9

# effect of storage and condition - BEST!!!
fit3 <- glmer(working ~ stor + cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit3) # AIC = 361.3

# effect of storage and condition (interacting)
fit4 <- glmer(working ~ stor * cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit4) # AIC = 362.8
```

#### Perfect samples (all 10 markers)

```{r model perfect}
genotypes$perfect <- as.factor(genotypes$perfect)

# no variables—just random effect
fit0 <- glmer(perfect ~ (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit0) # AIC = 425.7

# effect of condition only
fit1 <- glmer(perfect ~ cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1) # AIC = 407.1

# effect of condition only (coarse categories)
fit1.5 <- glmer(perfect ~ cond.coarse + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1.5) # AIC = 410.3

# effect of storage only
fit2 <- glmer(perfect ~ stor + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit2) # AIC = 400.8

# effect of storage and condition
fit3 <- glmer(perfect ~ stor + cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit3) # AIC = 382.2

# effect of storage and condition (interacting)
fit4 <- glmer(perfect ~ stor * cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit4) # AIC = 383.8
```

The best models (lowest AIC) for both working genotypes (with at least 8 amplifying markers) and perfect genotypes (all 10 markers working) include both storage and condition (but NOT the interaction between the two), as well as sample ID as a random effect. This suggests that both storage method and sample condition have important (but independent) effects on whether or not a sample works.

I tested two versions of condition score: one numerical (with 0.5 intervals), and one as a factor (coarser, with four categories), and the numerical one was better in both models.

## GLMMs for qPCR
```{r glmm qpcr}
# no variables—just random effect
fit0 <- lmer(extracted_conc ~ (1 | lab_id), data = genotypes)
summary(fit0)
AIC(fit0) # 2969.7

# effect of condition only
fit1 <- lmer(extracted_conc ~ cond + (1 | lab_id), data = genotypes)
summary(fit1)
AIC(fit1) # 2841.9

# effect of condition only (coarse categories)
fit1.5 <- lmer(extracted_conc ~ cond.coarse + (1 | lab_id), data = genotypes)
summary(fit1.5)
AIC(fit1.5) # 2826.9

# effect of storage only
fit2 <- lmer(extracted_conc ~ stor + (1 | lab_id), data = genotypes)
summary(fit2) 
AIC(fit2) # 2959.3

# effect of storage and condition
fit3 <- lmer(extracted_conc ~ stor + cond + (1 | lab_id), data = genotypes)
summary(fit3)
AIC(fit3) # 2831.4

# effect of storage and condition (interacting)
fit4 <- lmer(extracted_conc ~ stor * cond + (1 | lab_id), data = genotypes)
summary(fit4)
AIC(fit4) # 2822.3 *** BEST
```

