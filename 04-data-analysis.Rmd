---
title: "Data analysis"
author: "Kaitlyn"
date: "2019-11-20"
output: md_document
editor_options:
  chunk_output_type: console
---

## Set-up

Set working directory and load data.

```{r setup, message = F, warning = F}
library(lme4)
library(tidyverse)
library(here)
library(caret)
library(ROCR)

# import cleaned file
genotypes <- read_csv(here::here("data", "cleaned-triplicates-genotypes-qpcr.csv"))

genotypes$cond.coarse <- fct_collapse(as.factor(genotypes$cond), 
                                           Slimy = c("1", "1.5"),
                                           Wet = c("2", "2.5"),
                                           Shiny = c("3", "3.5"),
                                           Dull = c("4"))

genotypes$working <- as.factor(genotypes$working)
```

## GLMMs for microsat genotyping

We have a tricky modeling situation with the dependent variable—it is effectively a proportion (number of markers working out of 10 markers), and is bounded between 0 and 10 (or 0 and 1, if calculated as a true proportion). Furthermore, it is not normally distributed, but instead 0- and 1-inflated (most of the values are 0 or 1). When Googling, I ran into these ZOIB models (zero-one inflated beta models) which are a little confusing to me but seems promising?? https://journal.r-project.org/archive/2015/RJ-2015-019/RJ-2015-019.pdf They entail Bayesian inference and are a little tricky. I didn't go down this route.

We could instead treat the dependent variable as a binary variable (worked vs not worked, with the "worked" cut-off being 8 or 10), which simplifies our analysis greatly, and also may actually be more meaningful, since we don't actually care about the difference between 4 worked and 5 worked. So this is the route that I took. I'm open to feedback, and of course open to people playing around with the ZOIB models on their own (though am not sure I have the capacity to open that can of worms myself, ha).

I used sample (lab_id) as a random effect, to control for the fact that we tested the same samples in triplicate across methods. I tested both storage method and condition as fixed effects, in addition to running a null model (with only the random effect).

Dependent variable = binary, working samples (>= 8 markers)

```{r model working}
# no variables—just random effect
fit0 <- glmer(working ~ (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit0) # AIC = 405.7

# effect of condition only
fit1 <- glmer(working ~ cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1) # AIC = 386.5
AICc(fit1)

# effect of condition only (factor, fine categories)
fit1.25 <- glmer(working ~ as.factor(cond) + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1.25) # AIC = 389.2

# effect of condition only (factor, coarse categories) 
fit1.5 <- glmer(working ~ cond.coarse + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit1.5) # AIC = 389.0

# effect of storage only
fit2 <- glmer(working ~ stor + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit2) # AIC = 378.9

# effect of storage and condition - BEST!!!
fit3 <- glmer(working ~ stor + cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit3) # AIC = 361.3

# effect of storage and condition (interacting)
fit4 <- glmer(working ~ stor * cond + (1 | lab_id), family = binomial("logit"), data = genotypes)
summary(fit4) # AIC = 362.8
```

The best model (lowest AIC) for  working genotypes (with at least 8 amplifying markers) includes both storage and condition (but NOT the interaction between the two), as well as sample ID as a random effect. This suggests that both storage method and sample condition have important (but independent) effects on whether or not a sample works.

I tested two versions of condition score: one numerical (with 0.5 intervals), and one as a factor (coarser, with four categories), and the numerical one was better in both models.



## Goodness of fit tests

### Condition (categorical) + storage
```{r}
#########3 Area under Curve (AUC)
auc.data <- matrix(0, ncol = 1, nrow = 100)
auc.frame <- data.frame(auc.data)

x <- c(1:100)
for(i in c(1:100)){
  Train <- createDataPartition(genotypes$working, p=0.8, list=FALSE) #split the data set, using 80% of the sample for training
  training <- genotypes[ Train, ] #make training
  testing <- genotypes[ -Train, ] #make testing
                     
  best.model.train <- glmer(working ~ stor + cond + (1 | lab_id), 
                            family = binomial("logit"), 
                            data = training)
# Compute AUC for predicting Class with the full model
#AUC above .7 is good, above .8 is excellent fit
  prob <- predict(best.model.train, newdata = testing, type="response", allow.new.levels = TRUE)
  pred <- prediction(prob, testing$working)
  perf <- performance(pred, measure = "tpr", x.measure = "fpr")

  auc <- performance(pred, measure = "auc")
  auc <- auc@y.values[[1]]
  auc
  auc.frame$auc.frame[i] <- auc
}
 
mean(auc.frame$auc.frame) # 0.7699074
range(auc.frame$auc.frame) # 0.6040698 to 0.9045288
sd(auc.frame$auc.frame) # 0.06127213

#CONCLUSION: good model

```

### Condition (categorical) * storage
```{r}
#########3 Area under Curve (AUC)
auc.data <- matrix(0, ncol = 1, nrow = 100)
auc.frame <- data.frame(auc.data)

x <- c(1:100)
for(i in c(1:100)){
  Train <- createDataPartition(genotypes$working, p=0.8, list=FALSE) #split the data set, using 80% of the sample for training
  training <- genotypes[ Train, ] #make training
  testing <- genotypes[ -Train, ] #make testing
                     
  best.model.train <- glmer(working ~ stor * cond + (1 | lab_id), 
                            family = binomial("logit"), 
                            data = training)
# Compute AUC for predicting Class with the full model
#AUC above .7 is good, above .8 is excellent fit
  prob <- predict(best.model.train, newdata = testing, type="response", allow.new.levels = TRUE)
  pred <- prediction(prob, testing$working)
  perf <- performance(pred, measure = "tpr", x.measure = "fpr")

  auc <- performance(pred, measure = "auc")
  auc <- auc@y.values[[1]]
  auc
  auc.frame$auc.frame[i] <- auc
}
 
mean(auc.frame$auc.frame) # 0.7623688
range(auc.frame$auc.frame) # 0.6265496 to 0.8846591
sd(auc.frame$auc.frame) # 0.05798983

#CONCLUSION: good model

```

### Compare condition measures

##### Factor (continuous)
```{r}
set.seed(5)

#########3 Area under Curve (AUC)
auc.data <- matrix(0, ncol = 1, nrow = 100)
auc.frame <- data.frame(auc.data)

x <- c(1:100)
for(i in c(1:100)){
  Train <- createDataPartition(genotypes$working, p=0.8, list=FALSE) #split the data set, using 80% of the sample for training
  training <- genotypes[ Train, ] #make training
  testing <- genotypes[ -Train, ] #make testing
                     
  best.model.train <- glmer(working ~ cond + (1 | lab_id), 
                            family = binomial("logit"), 
                            data = training)
# Compute AUC for predicting Class with the full model
#AUC above .7 is good, above .8 is excellent fit
  prob <- predict(best.model.train, newdata = testing, type="response", allow.new.levels = TRUE)
  pred <- prediction(prob, testing$working)
  perf <- performance(pred, measure = "tpr", x.measure = "fpr")

  auc <- performance(pred, measure = "auc")
  auc <- auc@y.values[[1]]
  auc
  auc.frame$auc.frame[i] <- auc
}
 
mean(auc.frame$auc.frame) # 0.7142458
range(auc.frame$auc.frame) # 0.5097403 to 0.8238372
sd(auc.frame$auc.frame) # 0.06534265

#CONCLUSION: good model

```

##### Factor (coarse)
```{r}
set.seed(5)

#########3 Area under Curve (AUC)
auc.data <- matrix(0, ncol = 1, nrow = 100)
auc.frame <- data.frame(auc.data)

x <- c(1:100)
for(i in c(1:100)){
  Train <- createDataPartition(genotypes$working, p=0.8, list=FALSE) #split the data set, using 80% of the sample for training
  training <- genotypes[ Train, ] #make training
  testing <- genotypes[ -Train, ] #make testing
                     
  best.model.train <- glmer(working ~ cond.coarse + (1 | lab_id), 
                            family = binomial("logit"), 
                            data = training)
# Compute AUC for predicting Class with the full model
#AUC above .7 is good, above .8 is excellent fit
  prob <- predict(best.model.train, newdata = testing, type="response", allow.new.levels = TRUE)
  pred <- prediction(prob, testing$working)
  perf <- performance(pred, measure = "tpr", x.measure = "fpr")

  auc <- performance(pred, measure = "auc")
  auc <- auc@y.values[[1]]
  auc
  auc.frame$auc.frame[i] <- auc
}
 
mean(auc.frame$auc.frame) # 0.6986019
range(auc.frame$auc.frame) # 0.5151515 to 0.8273256
sd(auc.frame$auc.frame) # 0.0635215

#CONCLUSION: good model

```

#### Factor (fine)
```{r}
set.seed(5)

#########3 Area under Curve (AUC)
auc.data <- matrix(0, ncol = 1, nrow = 100)
auc.frame <- data.frame(auc.data)

x <- c(1:100)
for(i in c(1:100)){
  Train <- createDataPartition(genotypes$working, p=0.8, list=FALSE) #split the data set, using 80% of the sample for training
  training <- genotypes[ Train, ] #make training
  testing <- genotypes[ -Train, ] #make testing
                     
  best.model.train <- glmer(working ~ as.factor(cond) + (1 | lab_id), 
                            family = binomial("logit"), 
                            data = training)
# Compute AUC for predicting Class with the full model
#AUC above .7 is good, above .8 is excellent fit
  prob <- predict(best.model.train, newdata = testing, type="response", allow.new.levels = TRUE)
  pred <- prediction(prob, testing$working)
  perf <- performance(pred, measure = "tpr", x.measure = "fpr")

  auc <- performance(pred, measure = "auc")
  auc <- auc@y.values[[1]]
  auc
  auc.frame$auc.frame[i] <- auc
}
 
mean(auc.frame$auc.frame) # 0.7082125
range(auc.frame$auc.frame) # 0.5043290 to 0.8341493
sd(auc.frame$auc.frame) # 0.06033371

#CONCLUSION: good model

```

Continuous:
AIC = 386.5
ROC
mean = 0.7142458
range = 0.5097403 to 0.8238372
sd = 0.06534265

Categorical (coarse):
AIC = 389.0
ROC
mean = 0.6986019
range = 0.5151515 to 0.8273256
sd = 0.0635215

Categorical (fine):
AIC = 389.2
ROC
mean = 0.7082125
range = 0.5043290 to 0.8341493
sd = 0.06033371